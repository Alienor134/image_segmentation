{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image analysis\n",
    "import skimage.io\n",
    "import imageio\n",
    "import alienlab.plot\n",
    "from alienlab.improcessing import normalize, grey_to_rgb, make_binary\n",
    "import alienlab.segment\n",
    "from alienlab.fo import FramesOperator\n",
    "import alienlab.io\n",
    "\n",
    "\n",
    "#interactive widget packages\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USER ACTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Drag and drop a video file (.tif format) in the file section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"ENTER NAME OF THE FILE YOU DROPPED IN THE FILE SECTION HERE\"\n",
    "#file_path = askopenfilename(title = 'Select a video file') # pops up a window to select your file\n",
    "# uncomment this line if you use this jupyter notebook locally\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = True #option to output intermediary images in the segmentation process\n",
    "\n",
    "# Import video file in HQ and select ROI\n",
    "\n",
    "direc = os.path.split(file_path)[0]\n",
    "\n",
    "# Initialize plotting tools\n",
    "g = alienlab.plot.ShowFigure()\n",
    "g.figsize = (15,7)\n",
    "g.save_folder = \"images\"\n",
    "g.date = False\n",
    "p = alienlab.plot.PlotFigure()\n",
    "p.figsize = (15,7)\n",
    "p.save_folder = \"images\"\n",
    "p.date = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computed frames statistics in 1.513992 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# read the stacked frame. dim = NxHxW (N images in the video, Heigt, Width)\n",
    "\n",
    "frames_full = skimage.io.imread(file_path)\n",
    "\n",
    "#frames_full = np.stack([frames_full[:,:,1]]*10, 0) \n",
    "#uncomment this line if you have a single RGB image. The [:,:,1] stands for selection of the green channel\n",
    "\n",
    "FO = FramesOperator(frames_full)\n",
    "im = normalize(FO.frames[0], 0, 1)\n",
    "im = grey_to_rgb(im)*255\n",
    "\n",
    "#y, x = alienlab.io.select_roi(np.uint8(im)) #select area of interest\n",
    "#FO.x = x\n",
    "#FO.y = y\n",
    "#FO.crop() #crop image\n",
    "\n",
    "start_time = time.time()\n",
    "FO.compute_stats() #compute various statistical values on the frames and the pixels\n",
    "FO.normalize(0, 1)\n",
    "print(\"--- Computed frames statistics in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#FO.global_stats: each array has size N, number of frames and represents the stats of each frame\n",
    "#FO.frames_stats: each array has size FO.x, FO.y and is an image representing the N frames stats overlayed\n",
    "\n",
    "if show:\n",
    "    p.title = 'statistics'\n",
    "    p.xlabel = 'frame number'\n",
    "    p.ylabel = 'amplitude'\n",
    "    p.label_list = ['max', 'min', 'mean', 'std']\n",
    "    fig = p.plotting(np.asarray(FO.inds), [FO.global_stats['max'], \n",
    "                        FO.global_stats['min'], \n",
    "                        FO.global_stats['mean']])\n",
    "    p.save_name = 'frames_stats'\n",
    "    p.saving(fig)\n",
    "\n",
    "''' IMAGE SEGMENTATION '''\n",
    "\n",
    "# selection of the frames with high dynamics that will be used for the image segmentation process.\n",
    "# Let M be the highest value taken by a pixel in all the frames of the video. The frame F is kept for processing only if at\n",
    "# least one pixel in the frame F has a value above 0.8*M. \n",
    "FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 2751.5, 2207.5, -0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "plt.imshow(FO.frames[FO.selected_inds].sum(axis = 0), cmap = 'gray')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(contrast, autolevel, dist_max, dist_seg, disk_size, max_contrast, interact = True, showit = show):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.8) # Select only images with high intensity to increase contrast and lower computation time\n",
    "\n",
    "    #apply contrast filter to all frames\n",
    "    frames_contrast = FO.apply(skimage.filters.rank.enhance_contrast,  selem = skimage.morphology.disk(contrast))\n",
    "    #apply autolevel filter to all frames\n",
    "    frames_autolevel = FO.apply(skimage.filters.rank.autolevel, selem = skimage.morphology.disk(autolevel))\n",
    "    #sum the contrast images to get a reference grey-level contrast image\n",
    "    frame_contrast = np.sum(frames_contrast, axis = 0)\n",
    "    #sum the autolevel images to get a reference grey-level autolevel image\n",
    "    frame_autolevel = np.sum(frames_autolevel, axis = 0)\n",
    "    #obtain contrast mask from reference contrast image\n",
    "    mask_contrast = make_binary(frame_contrast, soft_hard = 1)\n",
    "    #otbain autolevel mask from reference autolevel image\n",
    "    mask_autolevel =  make_binary(frame_autolevel, soft_hard = 1)\n",
    "    #intersection of contrast aud autolevel masks\n",
    "    mask_intersect = mask_contrast * mask_autolevel\n",
    "    #clean the masks with a binary opening\n",
    "    mask_intersect = skimage.morphology.binary_opening(mask_intersect, selem = skimage.morphology.disk(disk_size))\n",
    "    #reference image of altitude for the watershed\n",
    "    auto_contrast = normalize(mask_intersect * frame_autolevel)\n",
    "    print(\"--- Computed binary mask in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    g.cmap = \"inferno\"\n",
    "    if showit:\n",
    "        g.figsize = (40,15)\n",
    "        g.title_list =  'contrast', 'contrast threshold', 'mask intersect','autolevel', 'autolevel threshold','segmentation image'\n",
    "        g.col_num = 3\n",
    "        fig = g.multi([frame_contrast, mask_contrast, mask_intersect, \n",
    "                       frame_autolevel, mask_autolevel,  auto_contrast])\n",
    "        g.save_name = 'Segmentation reference'\n",
    "        g.saving(fig)\n",
    "\n",
    "    start_time = time.time()\n",
    "    ref = auto_contrast\n",
    "    mask = mask_intersect\n",
    "    #locate the local maxima\n",
    "    local_maxi = alienlab.segment.local_maxima(auto_contrast, max_contrast, g,\n",
    "                                                     ref_distance = dist_max, mask = mask, show = showit)\n",
    "    #perform watershed segmentation\n",
    "    watershed_im_mask = alienlab.segment.watershed(ref, mask, local_maxi,\n",
    "                                                         g, ref_distance = dist_seg, show = False)\n",
    "    segmented = watershed_im_mask\n",
    "    print(\"--- Computed segmentation in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    if showit:\n",
    "        alienlab.segment.show_segmentation(FO, segmented, g)\n",
    "        \n",
    "    if interact == False:\n",
    "        return watershed_im_mask, FO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(segment_image, contrast = (1, 4), autolevel = (1, 10), dist_max = False, dist_seg = False, disk_size = (1, 4), max_contrast = (1,10), soft_hard = (0.1, 1.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computed binary mask in 15.022845 seconds ---\n",
      "--- Computed segmentation in 4.045800 seconds ---\n"
     ]
    }
   ],
   "source": [
    "mask, FO = segment_image(contrast = 2, autolevel = 5, dist_max = False, dist_seg=False, disk_size = 2, max_contrast = 3, interact = False, showit= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.cmap = \"flag\"\n",
    "fig = g.multi(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
